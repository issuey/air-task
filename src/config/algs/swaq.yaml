# --- UNMAS specific parameters ---

# use epsilon greedy action selector
action_selector: "epsilon_greedy"
epsilon_start: 1.0
epsilon_finish: 0.05
# epsilon_anneal_time: 50000
# 修改这个
epsilon_anneal_time: 50000 # 500000 for 6h_vs_8z

runner: "episode"

buffer_size: 5000
# 修改batch_size，原来没有这个属性的话默认batch_size是32
# batch_size: 128 # 修改这个之后效果变差了

# update the target network every {} episodes
target_update_interval: 200

# use the Q_Learner to train
agent_output_type: "q"
learner: "q_learner_critic"
double_q: True
mixer: "smix"
mixing_embed_dim: 32
hypernet_layers: 2
hypernet_embed: 64

agent: "att_rnn"
att_heads: 4
att_embed_dim: 32

lr: 0.001 # Learning rate for agents
td_lambda: 0.3

optimizer: 'adam'
grad_norm_clip: 20.0

name: "swaq"
